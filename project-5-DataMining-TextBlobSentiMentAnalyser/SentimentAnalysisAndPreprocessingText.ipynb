{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment Analysis and Preprocessing Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: Using the TextBlob Sentiment Analyzer (4)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the movie review data as a data frame and ensure that the data is loaded properly. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>review</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5814_8</td>\n",
       "      <td>1</td>\n",
       "      <td>With all this stuff going down at the moment w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2381_9</td>\n",
       "      <td>1</td>\n",
       "      <td>\\The Classic War of the Worlds\\\" by Timothy Hi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7759_3</td>\n",
       "      <td>0</td>\n",
       "      <td>The film starts with a manager (Nicholas Bell)...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3630_4</td>\n",
       "      <td>0</td>\n",
       "      <td>It must be assumed that those who praised this...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9495_8</td>\n",
       "      <td>1</td>\n",
       "      <td>Superbly trashy and wondrously unpretentious 8...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id  sentiment                                             review\n",
       "0  5814_8          1  With all this stuff going down at the moment w...\n",
       "1  2381_9          1  \\The Classic War of the Worlds\\\" by Timothy Hi...\n",
       "2  7759_3          0  The film starts with a manager (Nicholas Bell)...\n",
       "3  3630_4          0  It must be assumed that those who praised this...\n",
       "4  9495_8          1  Superbly trashy and wondrously unpretentious 8..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "# Read the TSV file\n",
    "df = pd.read_csv(\"labeledTrainData.tsv\", sep=\"\\t\")\n",
    "\n",
    "# Display the first few rows\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How many of each positive and negative reviews are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive reviews: 12500, Negative reviews: 12500\n"
     ]
    }
   ],
   "source": [
    "from textblob import TextBlob\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "import nltk\n",
    "\n",
    "# Download VADER lexicon if not already downloaded\n",
    "#nltk.download('vader_lexicon')\n",
    "\n",
    "# Step 1: Count actual positive and negative reviews\n",
    "positive_count = (df['sentiment'] == 1).sum()\n",
    "negative_count = (df['sentiment'] == 0).sum()\n",
    "print(f\"Positive reviews: {positive_count}, Negative reviews: {negative_count}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use TextBlob to classify each movie review as positive or negative. Assume that a polarity score greater than or equal to zero is a positive sentiment and less than 0 is a negative sentiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Use TextBlob to classify sentiment\n",
    "# TextBlob provides polarity (negative to positive: -1 to 1) \n",
    "def textblob_sentiment(text):\n",
    "    return 1 if TextBlob(text).sentiment.polarity >= 0 else 0\n",
    "\n",
    "df['textblob_pred'] = df['review'].apply(textblob_sentiment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check the accuracy of this model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TextBlob Accuracy: 68.52%\n"
     ]
    }
   ],
   "source": [
    "# Step 3: Check accuracy\n",
    "textblob_accuracy = (df['textblob_pred'] == df['sentiment']).mean()\n",
    "print(f\"TextBlob Accuracy: {textblob_accuracy:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is TextBlob better than random guessing? Yes\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Compare with random guessing (50% baseline)\n",
    "print(f\"Is TextBlob better than random guessing? {'Yes' if textblob_accuracy > 0.5 else 'No'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VADER Accuracy: 69.36%\n"
     ]
    }
   ],
   "source": [
    "# Step 5 (Extra Credit): Use VADER sentiment analysis\n",
    "sia = SentimentIntensityAnalyzer()\n",
    "\n",
    "def vader_sentiment(text):\n",
    "    return 1 if sia.polarity_scores(text)['compound'] >= 0 else 0\n",
    "\n",
    "df['vader_pred'] = df['review'].apply(vader_sentiment)\n",
    "\n",
    "# Check VADER accuracy\n",
    "vader_accuracy = (df['vader_pred'] == df['sentiment']).mean()\n",
    "print(f\"VADER Accuracy: {vader_accuracy:.2%}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is VADER better than random guessing? Yes\n"
     ]
    }
   ],
   "source": [
    "# Compare VADER with random guessing\n",
    "print(f\"Is VADER better than random guessing? {'Yes' if vader_accuracy > 0.5 else 'No'}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Prepping Text for a Custom Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Convert all text to lowercase letters.\n",
    "\r\n",
    "Remove punctuation and special characters from the text\n",
    ".\r\n",
    "Remove stop word\n",
    "s.\r\n",
    "Apply NLTK’s PorterStemm\n",
    "er.\r\n",
    "Create a bag-of-words matrix from your stemmed text (output from (4)), where each row is a word-count vector for a single movie review (see sections 5.3 & 6.8 in the Machine Learning with Python Cookbook). Display the dimensions of your bag-of-words matrix. The number of rows in this matrix should be the same as the number of rows in your original data fr\n",
    "ame.\r\n",
    "Create a term frequency-inverse document frequency (tf-idf) matrix from your stemmed text, for your movie reviews (see section 6.9 in the Machine Learning with Python Cookbook). Display the dimensions of your tf-idf matrix. These dimensions should be the same as your bag-of-words matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        stuff go moment mj ive start listen music watc...\n",
       "1        classic war world timothi hine entertain film ...\n",
       "2        film start manag nichola bell give welcom inve...\n",
       "3        must assum prais film greatest film opera ever...\n",
       "4        superbl trashi wondrous unpretenti 80 exploit ...\n",
       "                               ...                        \n",
       "24995    seem like consider gone imdb review film went ...\n",
       "24996    dont believ made film complet unnecessari firs...\n",
       "24997    guy loser cant get girl need build pick strong...\n",
       "24998    30 minut documentari buñuel made earli 1930 on...\n",
       "24999    saw movi child broke heart stori unfinish end ...\n",
       "Name: processed_review, Length: 25000, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "\n",
    "\n",
    "# Download necessary resources\n",
    "# nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt_tab')\n",
    "\n",
    "# Initialize NLTK tools\n",
    "stop_words = set(stopwords.words('english'))\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_text(text):\n",
    "    # Convert to lowercase\n",
    "    text = text.lower()\n",
    "    # Remove punctuation and special characters\n",
    "    text = text.translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "    # Tokenize words\n",
    "    tokens = word_tokenize(text)\n",
    "    # Remove stop words and apply stemming\n",
    "    tokens = [stemmer.stem(word) for word in tokens if word not in stop_words]\n",
    "    # Join back into a single string\n",
    "    return \" \".join(tokens)\n",
    "\n",
    "# Apply preprocessing to each review\n",
    "df['processed_review'] = df['review'].apply(preprocess_text)\n",
    "\n",
    "df['processed_review']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Bag-of-Words matrix\n",
    "\n",
    "CountVectorizer() in NLP\n",
    "CountVectorizer() is a text preprocessing tool from sklearn.feature_extraction.text \n",
    "that converts a collection of text documents into a matrix of token (word) counts.\n",
    "It is commonly used in Natural Language Processing (NLP) to transform raw text into numerical features for machine learning models.\n",
    "\n",
    "Tokenization – Splits text into individual words or n-grams.\n",
    "\n",
    "Lowercasing – Converts words to lowercase (by default).\n",
    "\n",
    "Stop Word Removal (optional) – Removes common words like \"the\", \"is\", etc.\n",
    "\n",
    "Word Frequency Count – Counts the occurrence of each unique word in the document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['00', '000', '0000000000001', ..., 'überannoy', 'überspi',\n",
       "       'üvegtigri'], dtype=object)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the CountVectorizer\n",
    "count = CountVectorizer()\n",
    "\n",
    "# Create the bag of words deature matrix\n",
    "bag_of_words = count.fit_transform(df['processed_review'])\n",
    "\n",
    "# show feature matrix\n",
    "bag_of_words\n",
    "\n",
    "print(bag_of_words.toarray())\n",
    "\n",
    "# show feature names\n",
    "count.get_feature_names_out()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create TF-IDF matrix\n",
    "\n",
    "In sentiment analysis, a TF-IDF (Term Frequency-Inverse Document Frequency) matrix represents the importance of words in documents, \n",
    "aiding in classifying text sentiment by highlighting words specific to a document or corpus. \n",
    "\n",
    "TF-IDF transforms text data into numerical vectors, where each row represents a document and each column represents a word (or term). \r\n",
    "The values in the matrix represent the TF-IDF scores for each word in each document.\n",
    "\n",
    "\n",
    "The model learns to associate specific TF-IDF scores with positive, negative, or neutral sentiments. \r\n",
    "When presented with new text, the model uses the TF-IDF scores to predict the sentiment of that text\n",
    "\n",
    "Term Frequency (TF): Measures how often a word appears in a document. \n",
    "\n",
    "\r\n",
    "Inverse Document Frequency (IDF): Measures how important a word is across a collection of documents (corpus).\n",
    "\n",
    " \r\n",
    "TF-IDF Score: Calculated by multiplying TF and IDF, resulting in a score that reflects the relevance of a word to a document within the corpus\n",
    "\n",
    "TfidfVectorizer() is a key component in natural language processing (NLP) used for text feature extraction. \n",
    "It converts raw text data into numerical representations that machine learning models can understand \n",
    "by applying Term Frequency-Inverse Document Frequency (TF-IDF) transformation.\n",
    "\n",
    "Tokenization – Splits text into individual words or n-grams.\n",
    "\n",
    "Lowercasing – Converts words to lowercase to maintain uniformity.\n",
    "\n",
    "Stop Word Removal (optional) – Removes common words like \"the\", \"is\", etc.\n",
    "\n",
    "TF Calculation – Counts the frequency of each word in a document.\n",
    "\n",
    "IDF Calculation – Gives higher weight to less common words across documents.\n",
    "\n",
    "TF-IDF Weight Calculation – Combines TF and IDF to represent the importance of words.\n",
    "\n",
    "Reduces the impact of frequently occurring words (like \"the\", \"is\") while keeping important words.\n",
    "\n",
    "Captures meaningful word importance for better text classification, clustering, and NLP tasks.\n",
    "\n",
    "Improves performance in text-based machine learning models by reducing noise.. .  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<25000x92345 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 2438862 stored elements in Compressed Sparse Row format>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_tfidf = tfidf_vectorizer.fit_transform(df['processed_review'])\n",
    "display(X_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bag-of-Words Matrix Shape: (25000, 92345)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Bag-of-Words Matrix Shape: {bag_of_words.shape}\")  # (num_reviews, num_unique_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape: (25000, 92345)\n"
     ]
    }
   ],
   "source": [
    "print(f\"TF-IDF Matrix Shape: {X_tfidf.shape}\")  # Should match BoW dimensions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
