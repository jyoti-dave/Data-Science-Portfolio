{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dimensionality Reduction and Feature Selection\n",
    "## Calculating PCA and Variance Threshold in a Linear Regression\n",
    "\n",
    "**DataSource** https://www.kaggle.com/c/house-prices-advanced-regression-techniques/data?select=train.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import the housing data as a data frame and ensure that the data is loaded properly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "   Id  MSSubClass MSZoning  LotFrontage  LotArea Street Alley LotShape  \\\n",
      "0   1          60       RL         65.0     8450   Pave   NaN      Reg   \n",
      "1   2          20       RL         80.0     9600   Pave   NaN      Reg   \n",
      "2   3          60       RL         68.0    11250   Pave   NaN      IR1   \n",
      "3   4          70       RL         60.0     9550   Pave   NaN      IR1   \n",
      "4   5          60       RL         84.0    14260   Pave   NaN      IR1   \n",
      "\n",
      "  LandContour Utilities  ... PoolArea PoolQC Fence MiscFeature MiscVal MoSold  \\\n",
      "0         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "1         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      5   \n",
      "2         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      9   \n",
      "3         Lvl    AllPub  ...        0    NaN   NaN         NaN       0      2   \n",
      "4         Lvl    AllPub  ...        0    NaN   NaN         NaN       0     12   \n",
      "\n",
      "  YrSold  SaleType  SaleCondition  SalePrice  \n",
      "0   2008        WD         Normal     208500  \n",
      "1   2007        WD         Normal     181500  \n",
      "2   2008        WD         Normal     223500  \n",
      "3   2006        WD        Abnorml     140000  \n",
      "4   2008        WD         Normal     250000  \n",
      "\n",
      "[5 rows x 81 columns]\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Load dataset\n",
    "file_path = \"train.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Drop the \"Id\" column and any features that are missing more than 40% of their values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "   MSSubClass MSZoning  LotFrontage  LotArea Street LotShape LandContour  \\\n",
      "0          60       RL         65.0     8450   Pave      Reg         Lvl   \n",
      "1          20       RL         80.0     9600   Pave      Reg         Lvl   \n",
      "2          60       RL         68.0    11250   Pave      IR1         Lvl   \n",
      "3          70       RL         60.0     9550   Pave      IR1         Lvl   \n",
      "4          60       RL         84.0    14260   Pave      IR1         Lvl   \n",
      "\n",
      "  Utilities LotConfig LandSlope  ... EnclosedPorch 3SsnPorch ScreenPorch  \\\n",
      "0    AllPub    Inside       Gtl  ...             0         0           0   \n",
      "1    AllPub       FR2       Gtl  ...             0         0           0   \n",
      "2    AllPub    Inside       Gtl  ...             0         0           0   \n",
      "3    AllPub    Corner       Gtl  ...           272         0           0   \n",
      "4    AllPub       FR2       Gtl  ...             0         0           0   \n",
      "\n",
      "  PoolArea MiscVal  MoSold  YrSold  SaleType  SaleCondition SalePrice  \n",
      "0        0       0       2    2008        WD         Normal    208500  \n",
      "1        0       0       5    2007        WD         Normal    181500  \n",
      "2        0       0       9    2008        WD         Normal    223500  \n",
      "3        0       0       2    2006        WD        Abnorml    140000  \n",
      "4        0       0      12    2008        WD         Normal    250000  \n",
      "\n",
      "[5 rows x 76 columns]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Drop Id column\n",
    "df.drop(columns=[\"Id\"], inplace=True)\n",
    "\n",
    "# Drop columns with more than 40% missing values\n",
    "threshold = len(df) * 0.4\n",
    "df = df.dropna(thresh=threshold, axis=1)\n",
    "\n",
    "# Display the first 5 rows\n",
    "print(\"First 5 rows:\")\n",
    "print(df.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. For numerical columns, fill in any missing data with the median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate numerical and categorical columns\n",
    "num_cols = df.select_dtypes(include=[\"int64\", \"float64\"]).columns\n",
    "cat_cols = df.select_dtypes(include=[\"object\"]).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. For numerical columns, fill in any missing data with the median value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
      "0             60         65.0     8450            7            5       2003   \n",
      "1             20         80.0     9600            6            8       1976   \n",
      "2             60         68.0    11250            7            5       2001   \n",
      "3             70         60.0     9550            7            5       1915   \n",
      "4             60         84.0    14260            8            5       2000   \n",
      "...          ...          ...      ...          ...          ...        ...   \n",
      "1455          60         62.0     7917            6            5       1999   \n",
      "1456          20         85.0    13175            6            6       1978   \n",
      "1457          70         66.0     9042            7            9       1941   \n",
      "1458          20         68.0     9717            5            6       1950   \n",
      "1459          20         75.0     9937            5            6       1965   \n",
      "\n",
      "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  WoodDeckSF  \\\n",
      "0             2003       196.0         706           0  ...           0   \n",
      "1             1976         0.0         978           0  ...         298   \n",
      "2             2002       162.0         486           0  ...           0   \n",
      "3             1970         0.0         216           0  ...           0   \n",
      "4             2000       350.0         655           0  ...         192   \n",
      "...            ...         ...         ...         ...  ...         ...   \n",
      "1455          2000         0.0           0           0  ...           0   \n",
      "1456          1988       119.0         790         163  ...         349   \n",
      "1457          2006         0.0         275           0  ...           0   \n",
      "1458          1996         0.0          49        1029  ...         366   \n",
      "1459          1965         0.0         830         290  ...         736   \n",
      "\n",
      "      OpenPorchSF  EnclosedPorch  3SsnPorch  ScreenPorch  PoolArea  MiscVal  \\\n",
      "0              61              0          0            0         0        0   \n",
      "1               0              0          0            0         0        0   \n",
      "2              42              0          0            0         0        0   \n",
      "3              35            272          0            0         0        0   \n",
      "4              84              0          0            0         0        0   \n",
      "...           ...            ...        ...          ...       ...      ...   \n",
      "1455           40              0          0            0         0        0   \n",
      "1456            0              0          0            0         0        0   \n",
      "1457           60              0          0            0         0     2500   \n",
      "1458            0            112          0            0         0        0   \n",
      "1459           68              0          0            0         0        0   \n",
      "\n",
      "      MoSold  YrSold  SalePrice  \n",
      "0          2    2008     208500  \n",
      "1          5    2007     181500  \n",
      "2          9    2008     223500  \n",
      "3          2    2006     140000  \n",
      "4         12    2008     250000  \n",
      "...      ...     ...        ...  \n",
      "1455       8    2007     175000  \n",
      "1456       2    2010     210000  \n",
      "1457       5    2010     266500  \n",
      "1458       4    2010     142125  \n",
      "1459       6    2008     147500  \n",
      "\n",
      "[1460 rows x 37 columns]\n"
     ]
    }
   ],
   "source": [
    "# Fill missing values\n",
    "df[num_cols] = df[num_cols].fillna(df[num_cols].median())\n",
    "df[cat_cols] = df[cat_cols].fillna(df[cat_cols].mode().iloc[0])\n",
    "\n",
    "# Display the first 5 rows of num_cols\n",
    "print(\"First 5 rows:\")\n",
    "print(df[num_cols])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "     MSZoning Street LotShape LandContour Utilities LotConfig LandSlope  \\\n",
      "0          RL   Pave      Reg         Lvl    AllPub    Inside       Gtl   \n",
      "1          RL   Pave      Reg         Lvl    AllPub       FR2       Gtl   \n",
      "2          RL   Pave      IR1         Lvl    AllPub    Inside       Gtl   \n",
      "3          RL   Pave      IR1         Lvl    AllPub    Corner       Gtl   \n",
      "4          RL   Pave      IR1         Lvl    AllPub       FR2       Gtl   \n",
      "...       ...    ...      ...         ...       ...       ...       ...   \n",
      "1455       RL   Pave      Reg         Lvl    AllPub    Inside       Gtl   \n",
      "1456       RL   Pave      Reg         Lvl    AllPub    Inside       Gtl   \n",
      "1457       RL   Pave      Reg         Lvl    AllPub    Inside       Gtl   \n",
      "1458       RL   Pave      Reg         Lvl    AllPub    Inside       Gtl   \n",
      "1459       RL   Pave      Reg         Lvl    AllPub    Inside       Gtl   \n",
      "\n",
      "     Neighborhood Condition1 Condition2  ... KitchenQual Functional  \\\n",
      "0         CollgCr       Norm       Norm  ...          Gd        Typ   \n",
      "1         Veenker      Feedr       Norm  ...          TA        Typ   \n",
      "2         CollgCr       Norm       Norm  ...          Gd        Typ   \n",
      "3         Crawfor       Norm       Norm  ...          Gd        Typ   \n",
      "4         NoRidge       Norm       Norm  ...          Gd        Typ   \n",
      "...           ...        ...        ...  ...         ...        ...   \n",
      "1455      Gilbert       Norm       Norm  ...          TA        Typ   \n",
      "1456       NWAmes       Norm       Norm  ...          TA       Min1   \n",
      "1457      Crawfor       Norm       Norm  ...          Gd        Typ   \n",
      "1458        NAmes       Norm       Norm  ...          Gd        Typ   \n",
      "1459      Edwards       Norm       Norm  ...          TA        Typ   \n",
      "\n",
      "     FireplaceQu GarageType GarageFinish GarageQual GarageCond PavedDrive  \\\n",
      "0             Gd     Attchd          RFn         TA         TA          Y   \n",
      "1             TA     Attchd          RFn         TA         TA          Y   \n",
      "2             TA     Attchd          RFn         TA         TA          Y   \n",
      "3             Gd     Detchd          Unf         TA         TA          Y   \n",
      "4             TA     Attchd          RFn         TA         TA          Y   \n",
      "...          ...        ...          ...        ...        ...        ...   \n",
      "1455          TA     Attchd          RFn         TA         TA          Y   \n",
      "1456          TA     Attchd          Unf         TA         TA          Y   \n",
      "1457          Gd     Attchd          RFn         TA         TA          Y   \n",
      "1458          Gd     Attchd          Unf         TA         TA          Y   \n",
      "1459          Gd     Attchd          Fin         TA         TA          Y   \n",
      "\n",
      "     SaleType SaleCondition  \n",
      "0          WD        Normal  \n",
      "1          WD        Normal  \n",
      "2          WD        Normal  \n",
      "3          WD       Abnorml  \n",
      "4          WD        Normal  \n",
      "...       ...           ...  \n",
      "1455       WD        Normal  \n",
      "1456       WD        Normal  \n",
      "1457       WD        Normal  \n",
      "1458       WD        Normal  \n",
      "1459       WD        Normal  \n",
      "\n",
      "[1460 rows x 39 columns]\n"
     ]
    }
   ],
   "source": [
    "# Display the first 5 rows of cat_cols\n",
    "print(\"First 5 rows:\")\n",
    "print(df[cat_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Convert categorical columns to dummies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 2 rows:\n",
      "   MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
      "0          60         65.0     8450            7            5       2003   \n",
      "1          20         80.0     9600            6            8       1976   \n",
      "\n",
      "   YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_ConLI  \\\n",
      "0          2003       196.0         706           0  ...           False   \n",
      "1          1976         0.0         978           0  ...           False   \n",
      "\n",
      "   SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
      "0           False         False         False         True   \n",
      "1           False         False         False         True   \n",
      "\n",
      "   SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
      "0                  False                 False                 False   \n",
      "1                  False                 False                 False   \n",
      "\n",
      "   SaleCondition_Normal  SaleCondition_Partial  \n",
      "0                  True                  False  \n",
      "1                  True                  False  \n",
      "\n",
      "[2 rows x 235 columns]\n"
     ]
    }
   ],
   "source": [
    "# Convert categorical columns to dummies\n",
    "df = pd.get_dummies(df, drop_first=True)\n",
    "\n",
    "# Split into features and target\n",
    "X = df.drop(columns=[\"SalePrice\"])\n",
    "# Display the first 2 rows\n",
    "print(\"First 2 rows:\")\n",
    "print(X.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 rows:\n",
      "0    208500\n",
      "1    181500\n",
      "Name: SalePrice, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "y = df[\"SalePrice\"]\n",
    "# Display the first 5 rows\n",
    "print(\"First 5 rows:\")\n",
    "print(y.head(2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Split the data into a training and test set, where the SalePrice column is the target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 2 rows:\n",
      "      MSSubClass  LotFrontage  LotArea  OverallQual  OverallCond  YearBuilt  \\\n",
      "254           20         70.0     8400            5            6       1957   \n",
      "1066          60         59.0     7837            6            7       1993   \n",
      "\n",
      "      YearRemodAdd  MasVnrArea  BsmtFinSF1  BsmtFinSF2  ...  SaleType_ConLI  \\\n",
      "254           1957         0.0         922           0  ...           False   \n",
      "1066          1994         0.0           0           0  ...           False   \n",
      "\n",
      "      SaleType_ConLw  SaleType_New  SaleType_Oth  SaleType_WD  \\\n",
      "254            False         False         False         True   \n",
      "1066           False         False         False         True   \n",
      "\n",
      "      SaleCondition_AdjLand  SaleCondition_Alloca  SaleCondition_Family  \\\n",
      "254                   False                 False                 False   \n",
      "1066                  False                 False                 False   \n",
      "\n",
      "      SaleCondition_Normal  SaleCondition_Partial  \n",
      "254                   True                  False  \n",
      "1066                  True                  False  \n",
      "\n",
      "[2 rows x 235 columns]\n"
     ]
    }
   ],
   "source": [
    "# Split into train and test sets\n",
    "# X_train = input features (independent variables)\n",
    "\n",
    "# y_train = output to predict (dependent variable)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Display the first 2 rows\n",
    "print(\"First 2 rows:\")\n",
    "print(X_train.head(2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 2 rows:\n",
      "254     145000\n",
      "1066    178000\n",
      "Name: SalePrice, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Display the first 2 rows\n",
    "print(\"First 2 rows:\")\n",
    "print(y_train.head(2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Run a linear regression and report the R2-value and RMSE on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Data - R2: 0.6434086516194634\n",
      "Original Data - RMSE: 52298.871543652116\n"
     ]
    }
   ],
   "source": [
    "# 2. Linear Regression on Original Data\n",
    "\n",
    "# Run linear regression\n",
    "lr = LinearRegression()\n",
    "\n",
    "#train (fit) the model on training data:\n",
    "# After training, make predictions on the test set (X_test).\n",
    "# y_pred is what the model thinks the outputs should be.\n",
    "lr.fit(X_train, y_train)\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# R2 and RMSE\n",
    "\n",
    "# evaluate how good your model's predictions are:\n",
    "\n",
    "# R² Score (r2_score): Measures how much of the variation in y_test your model explains.\n",
    "\n",
    "# Ranges from -∞ to 1. Closer to 1 = better.\n",
    "\n",
    "# RMSE (Root Mean Squared Error): Tells you how far off, on average, your predictions are.\n",
    "\n",
    "# Lower RMSE = better.\n",
    "r2_original = r2_score(y_test, y_pred)\n",
    "rmse_original = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "print(\"Original Data - R2:\", r2_original)\n",
    "print(\"Original Data - RMSE:\", rmse_original)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "The performance on the original data was:\n",
    "\n",
    "R²: 0.6434\n",
    "\n",
    "RMSE: 52,298.87\n",
    "\n",
    "This suggests that the original dataset, with all features included, provides a reasonable model performance. The R² of 0.6434 indicates that around 64.34% of the variance in the target variable (SalePrice) is explained by the model, which is a moderate fit. The RMSE of 52,298.87 means the model's predictions are, on average, off by about that amount from the actual sale prices.\n",
    "\n",
    "Summary of Findings:\n",
    "Original data provides decent performance (R²: 0.6434) with reasonable error (RMSE: 52,298.87).\n",
    "\n",
    "PCA transformation (90% variance) resulted in worse performance (R²: 0.0635, RMSE: 84,754.58) because reducing the dataset to just 1 principal component likely stripped away too much important information.\n",
    "\n",
    "High variance features (with variance > 0.1 after min-max scaling) gave an improvement (R²: 0.6556, RMSE: 51,393.43), suggesting that retaining features with higher variance leads to a better model.\n",
    "\n",
    "Key Takeaways:\n",
    "\n",
    "Dimensionality reduction via PCA may not always be beneficial if it results in the loss of important features.\n",
    "\n",
    "Retaining features with higher variance appears to have a more beneficial impact on model performance than reducing dimensions through PCA.\n",
    "\n",
    "The original data with no transformation produced solid results, showing that sometimes the raw features may provide enough information to achieve good predictive accuracy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Fit and transform the training features with a PCA so that 90% of the variance is retained "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PCA Transformation (90% Variance)\n",
    "\n",
    "pca = PCA(n_components=0.90)\n",
    "X_train_pca = pca.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9 How many features are in the PCA-transformed matrix?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of PCA features: 1\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of PCA features:\", X_train_pca.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10 Transform but DO NOT fit the test features with the same PCA.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_pca = pca.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fact that PCA transformed the data into just 1 feature indicates that, after reducing the dimensionality to retain 90% of the variance, only one principal component is sufficient to represent most of the variability in the dataset.\n",
    "\n",
    "This suggests that the original data may have been very collinear or highly dependent on one or a few key factors. It could also mean that a large portion of the variance in the original features can be explained by a single combination of features in the transformed space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 11. Repeat step 7 with your PCA transformed data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Data - R2: 0.06348978217577883\n",
      "PCA Data - RMSE: 84754.5802129634\n"
     ]
    }
   ],
   "source": [
    "# Linear Regression on PCA Data\n",
    "\n",
    "lr_pca = LinearRegression()\n",
    "lr_pca.fit(X_train_pca, y_train)\n",
    "y_pred_pca = lr_pca.predict(X_test_pca)\n",
    "\n",
    "r2_pca = r2_score(y_test, y_pred_pca)\n",
    "rmse_pca = np.sqrt(mean_squared_error(y_test, y_pred_pca))\n",
    "print(\"PCA Data - R2:\", r2_pca)\n",
    "print(\"PCA Data - RMSE:\", rmse_pca)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The PCA-transformed data has an R² of 0.0635 and an RMSE of 84,754.58, which shows a significant decline in performance compared to both the original and high-variance models. Here’s an analysis of these results:\n",
    "\n",
    "Interpretation:\n",
    "R² of 0.0635 means that the model can only explain about 6.35% of the variance in the target variable (SalePrice). This is much lower than the original data (R² = 0.6434) and high-variance data (R² = 0.6556).\n",
    "\n",
    "RMSE of 84,754.58 suggests that the model’s predictions are now about 84,754 units off from the true sale prices, which is a much larger error compared to the original and high-variance data (RMSE = 52,298.87 and 51,393.43, respectively).\n",
    "\n",
    "What this means for the model:\n",
    "Since working with only one principal component (PC), the model has limited flexibility in representing the complexities of the data.\n",
    "\n",
    "The drop in R² (0.0635) and increase in RMSE (84,754.58) aligns with this, as reducing the features to just one component may oversimplify the problem, losing important information necessary for accurate predictions.\n",
    "\n",
    "Why this might have happened:\n",
    "PCA reduces dimensionality by transforming features into principal components, which, while retaining most of the variance, can lose some of the original features' meaningful context or relationships with the target variable.\n",
    "\n",
    "The fact that we have retained 90% of the variance implies that while most of the original data's information is preserved, the PCA transformation could have obscured important relationships, reducing the model's predictive power.\n",
    "\n",
    "Conclusion:\n",
    "PCA might not have been the best approach in this case, especially if retaining specific features' relationships with the target variable is crucial for prediction accuracy. The loss of interpretability and the transformation of features into principal components may have hindered the model’s performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 13. Find the min-max scaled features in your training set that have a variance above 0.1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5  Min-Max Scaling + Variance Threshold\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Convert back to DataFrame for variance check\n",
    "X_train_scaled_df = pd.DataFrame(X_train_scaled, columns=X.columns)\n",
    "\n",
    "# Variance threshold\n",
    "high_variance_cols = X_train_scaled_df.loc[:, X_train_scaled_df.var() > 0.1].columns\n",
    "\n",
    "# Subset with high variance features\n",
    "X_train_highvar = X_train_scaled_df[high_variance_cols]\n",
    "X_test_highvar = pd.DataFrame(X_test_scaled, columns=X.columns)[high_variance_cols]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Transform but DO NOT fit the test features with the same steps applied in steps 11 and 12."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_var = LinearRegression()\n",
    "lr_var.fit(X_train_highvar, y_train)\n",
    "y_pred_var = lr_var.predict(X_test_highvar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Repeat step 7 with the high variance data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Variance Data - R2: 0.6556489506346084\n",
      "High Variance Data - RMSE: 51393.43224984833\n"
     ]
    }
   ],
   "source": [
    "r2_var = r2_score(y_test, y_pred_var)\n",
    "rmse_var = np.sqrt(mean_squared_error(y_test, y_pred_var))\n",
    "print(\"High Variance Data - R2:\", r2_var)\n",
    "print(\"High Variance Data - RMSE:\", rmse_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the High Variance Data approach has an R² of 0.6556 and an RMSE of 51,393.43, which confirms that selecting features based on high variance improved the model’s performance slightly over the original data.\n",
    "\n",
    "Here’s a brief interpretation of this outcome:\n",
    "\n",
    "Interpretation:\n",
    "R² of 0.6556 indicates that the model can explain approximately 65.56% of the variance in the target variable (SalePrice), which is an improvement over the original model (R² = 0.6434).\n",
    "\n",
    "RMSE of 51,393.43 suggests that the model's predictions are now, on average, about 51,393 units off from the true sale prices. Although there is still error, this is a notable reduction from the RMSE of 52,298.87 on the original data.\n",
    "\n",
    "Conclusion:\n",
    "Using high variance features is proving to be a useful approach for improving model performance. It seems that by focusing on the most informative features (those with higher variance), the model has better predictive power and accuracy, as reflected in both the R² and RMSE."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 16. Summarize your findings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Summary of R2 and RMSE:\n",
      "Original Data      => R2: 0.6434, RMSE: 52298.87\n",
      "PCA (90% variance) => R2: 0.0635, RMSE: 84754.58\n",
      "High Variance      => R2: 0.6556, RMSE: 51393.43\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nSummary of R2 and RMSE:\")\n",
    "print(f\"Original Data      => R2: {r2_original:.4f}, RMSE: {rmse_original:.2f}\")\n",
    "print(f\"PCA (90% variance) => R2: {r2_pca:.4f}, RMSE: {rmse_pca:.2f}\")\n",
    "print(f\"High Variance      => R2: {r2_var:.4f}, RMSE: {rmse_var:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summary of Results<br>\n",
    "\n",
    "Model\tR² Score\tRMSE\tNotes <br>\n",
    "Original Data\t0.6434\t52,298.87\tPerforms reasonably well but may have overfitting or high complexity<br>\n",
    "PCA (90% Variance)\t0.0635\t84,754.58\tSignificantly worse performance, likely due to too much dimensionality reduction<br>\n",
    "High Variance Features\t0.6556\t51,393.43\tSlightly better performance than original features by focusing on high-variance data<br>\n",
    "Analysis:\n",
    "Original Data:\n",
    "\n",
    "R² = 0.6434 suggests that the model is able to explain around 64% of the variance in the target variable (SalePrice), which is decent.<br>\n",
    "\n",
    "RMSE = 52,298.87 reflects the average error in prediction. Given the dataset might include houses with high price variability, this could be reasonable.<br>\n",
    "\n",
    "PCA (90% Variance):<br>\n",
    "\n",
    "R² = 0.0635 and RMSE = 84,754.58 indicate poor performance. The drastic drop in performance after applying PCA suggests that reducing the dimensionality to retain only 90% of variance results in losing important features and relationships in the data.<br>\n",
    "\n",
    "PCA should generally improve performance if it simplifies the model without losing key information, but in this case, it seems the PCA transformation is detrimental.<br>\n",
    "\n",
    "High Variance Features:<br>\n",
    "\n",
    "R² = 0.6556 shows a small improvement over the original features, likely because this approach keeps only the most impactful features (those with high variance).<br>\n",
    "\n",
    "RMSE = 51,393.43 is the lowest of the three, indicating that the focus on high-variance features improves predictions slightly.<br>\n",
    "\n",
    "Conclusion:<br>\n",
    "The original data performs well but might benefit from feature selection or regularization to improve generalization.<br>\n",
    "\n",
    "PCA did not work well for this dataset, possibly due to a loss of relevant information when reducing dimensions.<br>\n",
    "\n",
    "High variance features proved to be a good compromise, yielding the best balance between model complexity and performance."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
